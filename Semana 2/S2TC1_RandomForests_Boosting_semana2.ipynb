{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sbn2ozJNlNgD"
   },
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwHTizdwlNgE"
   },
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPRuerh1lNgG"
   },
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gM6Yyx5blNgG"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "executionInfo": {
     "elapsed": 4054,
     "status": "ok",
     "timestamp": 1743878116349,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "tX_pKkPKlNgI",
    "outputId": "e46c3677-51f0-4b84-ea29-5fe49590688f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21995</td>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13995</td>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17941</td>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12493</td>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7994</td>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  \\\n",
       "7    21995  2014     6480    False       False        False      True   \n",
       "11   13995  2014    39972    False       False        False     False   \n",
       "167  17941  2016    18989    False       False        False     False   \n",
       "225  12493  2014    51330    False       False        False      True   \n",
       "270   7994  2007   116065    False        True        False     False   \n",
       "\n",
       "     M_CamryLE  M_CamrySE  M_CamryXLE  \n",
       "7        False      False       False  \n",
       "11        True      False       False  \n",
       "167      False       True       False  \n",
       "225      False      False       False  \n",
       "270      False      False       False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "# Lectura de la información de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
    "\n",
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data = data.drop(['Model'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1743878116397,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "EqmhnhtHlNgJ",
    "outputId": "e5bb5274-7d86-4e69-bae9-388078d5a526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10495 entries, 7 to 399976\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   Price        10495 non-null  int64\n",
      " 1   Year         10495 non-null  int64\n",
      " 2   Mileage      10495 non-null  int64\n",
      " 3   M_Camry      10495 non-null  bool \n",
      " 4   M_Camry4dr   10495 non-null  bool \n",
      " 5   M_CamryBase  10495 non-null  bool \n",
      " 6   M_CamryL     10495 non-null  bool \n",
      " 7   M_CamryLE    10495 non-null  bool \n",
      " 8   M_CamrySE    10495 non-null  bool \n",
      " 9   M_CamryXLE   10495 non-null  bool \n",
      "dtypes: bool(7), int64(3)\n",
      "memory usage: 399.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hkd4xcHulNgJ"
   },
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['Price']\n",
    "X = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8YvFj8jllNgK"
   },
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSQwWc7hlNgL"
   },
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el RMSE y MAE del modelo en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1743878636287,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "vCYIkSJ7lNgL",
    "outputId": "c1b0b6a8-9610-4205-ae71-3729b4ffaa0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1935.19\n",
      "MAE: 1461.35\n"
     ]
    }
   ],
   "source": [
    "# Celda 1\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "# Función para calcular ganancia por reducción de varianza\n",
    "def variance_gain(X_col, y, split):\n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "\n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "\n",
    "    if n_l == 0 or n_r == 0:\n",
    "        return 0\n",
    "\n",
    "    var_total = y.var()\n",
    "    var_l = y_l.var()\n",
    "    var_r = y_r.var()\n",
    "\n",
    "    gain = var_total - (n_l / (n_l + n_r) * var_l + n_r / (n_l + n_r) * var_r)\n",
    "\n",
    "    return gain\n",
    "\n",
    "# Función para encontrar el mejor split\n",
    "def best_split_reg(X, y, num_pct=10):\n",
    "    best_split = [0, 0, -np.inf]  # j, split, gain\n",
    "\n",
    "    for j in range(X.shape[1]):\n",
    "        col = X.iloc[:, j]\n",
    "\n",
    "        # Ignorar columnas binarias o booleanas\n",
    "        if col.nunique() <= 2:\n",
    "            continue\n",
    "\n",
    "        splits = np.percentile(col, np.linspace(0, 100, num_pct + 2)[1:-1])\n",
    "        splits = np.unique(splits)\n",
    "\n",
    "        for split in splits:\n",
    "            gain = variance_gain(col, y, split)\n",
    "\n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "\n",
    "    return best_split\n",
    "\n",
    "# Función para hacer crecer el árbol manualmente (regresión)\n",
    "def tree_grow_reg(X, y, level=0, min_gain=0.00001, max_depth=3, num_pct=10):\n",
    "    if X.shape[0] == 1:\n",
    "        return dict(y_pred=y.iloc[0], level=level, split=-1, n_samples=1, gain=0)\n",
    "\n",
    "    j, split, gain = best_split_reg(X, y, num_pct)\n",
    "    y_pred = y.mean()\n",
    "\n",
    "    tree = dict(y_pred=y_pred, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "\n",
    "    # Criterios de parada\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None and level >= max_depth:\n",
    "        return tree\n",
    "\n",
    "    # Crear divisiones\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "\n",
    "    tree['split'] = [j, split]\n",
    "    tree['sl'] = tree_grow_reg(X_l, y_l, level + 1, min_gain, max_depth, num_pct)\n",
    "    tree['sr'] = tree_grow_reg(X_r, y_r, level + 1, min_gain, max_depth, num_pct)\n",
    "\n",
    "    return tree\n",
    "\n",
    "# Función para predecir\n",
    "def tree_predict_reg(X, tree):\n",
    "    predicted = np.zeros(X.shape[0])\n",
    "\n",
    "    if tree['split'] == -1:\n",
    "        predicted[:] = tree['y_pred']\n",
    "    else:\n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] > 0:\n",
    "            predicted[filter_l] = tree_predict_reg(X_l, tree['sl'])\n",
    "        if X_r.shape[0] > 0:\n",
    "            predicted[~filter_l] = tree_predict_reg(X_r, tree['sr'])\n",
    "\n",
    "    return predicted\n",
    "tree = tree_grow_reg(X_train, y_train, max_depth=3)\n",
    "y_pred = tree_predict_reg(X_test, tree)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1743867480985,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "gsBB8SY2lNgM",
    "outputId": "c6341f1f-11ec-4b91-cc36-c41d2c84ffbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidad máxima del árbol: 3\n"
     ]
    }
   ],
   "source": [
    "def get_max_depth(tree):\n",
    "    if tree['split'] == -1:\n",
    "        return tree['level']\n",
    "    else:\n",
    "        return max(get_max_depth(tree['sl']), get_max_depth(tree['sr']))\n",
    "max_depth = get_max_depth(tree)\n",
    "print(f\"Profundidad máxima del árbol: {max_depth}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKscTm7FlNgN"
   },
   "source": [
    "El árbol de decisión manual entrenado para predecir el precio de los automóviles (Camry) con una profundidad máxima de 3, una ganancia minima de 0.00001 y con 10 particiones por variable mostró los siguientes resultados sobre el conjunto de prueba:\n",
    "\n",
    "MAE (Error absoluto medio): 1935.19\n",
    "Este valor representa, en promedio, cuánto se desvía la predicción del modelo respecto al precio real del auto. Un MAE bajo indica que el modelo tiene un buen desempeño al acercarse a los valores reales.\n",
    "\n",
    "RMSE (Raíz del error cuadrático medio): 1461.35\n",
    "Este error penaliza más fuertemente los errores grandes que el MAE, por lo que si hay valores atípicos mal predichos, este métrico será más alto.\n",
    "\n",
    "En general, el modelo presenta un desempeño razonable teniendo en cuenta que:\n",
    "\n",
    "Se utilizó un árbol de decisión muy sencillo (profundidad 3).\n",
    "\n",
    "No se aplicó poda ni ajustes más complejos.\n",
    "\n",
    "El árbol proporciona interpretabilidad (es fácil de explicar qué decisiones se tomaron en cada nodo), pero su capacidad predictiva podría mejorarse con un mayor número de niveles, técnicas como boosting o bagging, o modelos más complejos como regresión lineal o redes neuronales.\n",
    "\n",
    "Precisión\tEl error absoluto promedio está dentro de un rango aceptable dependiendo del rango de precios del dataset.\n",
    "Profundidad\tEl árbol tiene una profundidad máxima de 3, lo cual limita la capacidad del modelo para aprender patrones complejos. Esto se hizo probablemente para evitar sobreajuste.\n",
    "Generalización\tDado que el error no es excesivamente alto y el modelo es simple, parece tener una buena capacidad de generalización, aunque podría mejorar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOVSYfcplNgN"
   },
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de regresión y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1743867572021,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "asWzWRpzlNgO",
    "outputId": "99982192-36cc-4c0f-e4e1-b25b42ef8d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE por árbol individual:\n",
      "Árbol 0: RMSE = 2141.61\n",
      "Árbol 1: RMSE = 2136.35\n",
      "Árbol 2: RMSE = 2122.72\n",
      "Árbol 3: RMSE = 2087.28\n",
      "Árbol 4: RMSE = 2168.52\n",
      "Árbol 5: RMSE = 2113.88\n",
      "Árbol 6: RMSE = 2127.93\n",
      "Árbol 7: RMSE = 2184.41\n",
      "Árbol 8: RMSE = 2138.11\n",
      "Árbol 9: RMSE = 2132.10\n",
      "\n",
      " Desempeño del modelo Bagging (10 árboles):\n",
      " RMSE = 1796.44\n",
      " MAE = 1340.02\n"
     ]
    }
   ],
   "source": [
    "# Celda 2import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "# Número de árboles\n",
    "n_B = 10\n",
    "\n",
    "# Crear muestras bootstrap\n",
    "np.random.seed(123)\n",
    "samples = [np.random.choice(a=X_train.index, size=len(X_train), replace=True) for _ in range(n_B)]\n",
    "\n",
    "# Crear modelo base\n",
    "treereg = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "\n",
    "# DataFrame para guardar predicciones de cada árbol\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=range(n_B))\n",
    "\n",
    "# Entrenamiento y predicción para cada muestra bootstrap\n",
    "for i, sample in enumerate(samples):\n",
    "    X_sample = X_train.loc[sample]\n",
    "    y_sample = y_train.loc[sample]\n",
    "    treereg.fit(X_sample, y_sample)\n",
    "    y_pred.iloc[:, i] = treereg.predict(X_test)\n",
    "\n",
    "# Desempeño individual de cada árbol\n",
    "print(\" RMSE por árbol individual:\")\n",
    "for i in range(n_B):\n",
    "    rmse_i = np.sqrt(mean_squared_error(y_test, y_pred.iloc[:, i]))\n",
    "    print(f'Árbol {i}: RMSE = {rmse_i:.2f}')\n",
    "\n",
    "# Promedio de predicciones\n",
    "y_pred_mean = y_pred.mean(axis=1)\n",
    "\n",
    "# Evaluación del modelo Bagging (con promedio)\n",
    "rmse_bagging = np.sqrt(mean_squared_error(y_test, y_pred_mean))\n",
    "mae_bagging = mean_absolute_error(y_test, y_pred_mean)\n",
    "\n",
    "print(f\"\\n Desempeño del modelo Bagging (10 árboles):\")\n",
    "print(f\" RMSE = {rmse_bagging:.2f}\")\n",
    "print(f\" MAE = {mae_bagging:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UNG6r_mlNgO"
   },
   "source": [
    "Este modelo de bagging crea 10 árboles de decisión independientes entrenados en diferentes muestras bootstrap. Luego promedia sus predicciones para reducir la varianza del modelo y mejorar la generalización.\n",
    "•\tEn general, cada árbol tiene un desempeño variable debido al muestreo aleatorio.\n",
    "•\tAl promediar las predicciones, el error del modelo disminuye, lo cual es una característica esperada del bagging.\n",
    "•\tComo se puede observar el RMSE fue infrior al arbo manual 1796 vs 1935 del arbol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NqDF2ZilNgP"
   },
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de regresión y el parámetro `max_features` igual a `log(n_features)` y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99,
     "status": "ok",
     "timestamp": 1743867604749,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "ptD72KS8lNgP",
    "outputId": "365456c7-f64c-4540-bba9-33b3e23e4cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo Bagging (sklearn): 2768.52\n",
      "MAE del modelo Bagging (sklearn): 2160.78\n"
     ]
    }
   ],
   "source": [
    "# Celda 3\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# -------------------------------\n",
    "# Modelo Bagging con sklearn\n",
    "# -------------------------------\n",
    "\n",
    "# Calcular log(n_features)\n",
    "n_features = X_train.shape[1]\n",
    "max_features = int(np.log(n_features))\n",
    "\n",
    "# Definir modelo Bagging\n",
    "\n",
    "bagging_model = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=5),\n",
    "    n_estimators=10,\n",
    "    max_features=max_features,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar modelo\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_sklearn = bagging_model.predict(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# Métricas de desempeño\n",
    "# -------------------------------\n",
    "rmseBL = np.sqrt(mean_squared_error(y_test, y_pred_sklearn))\n",
    "maeBL = mean_absolute_error(y_test, y_pred_sklearn)\n",
    "\n",
    "print(f\"RMSE del modelo Bagging (sklearn): {rmseBL:.2f}\")\n",
    "print(f\"MAE del modelo Bagging (sklearn): {maeBL:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaoEjuZclNgQ"
   },
   "source": [
    "El modelo de Bagging implementado con la librería sklearn obtuvo un RMSE de 2768.35 y un MAE de 2160.76 en el conjunto de prueba. Este modelo usó 10 árboles de regresión con max_features = log(n_features), lo que limitó la cantidad de variables que cada árbol podía ver al momento de entrenarse. Comparado con los otros enfoques: El bagging manual superó al modelo de sklearn, mostrando un RMSE mucho menor (1796.44 vs 2768.52). Esto se puede explicar por el parámetro max_features = log(n_features), que reduce la diversidad de información disponible para cada árbol. Aunque esta configuración puede ser útil para reducir el sobreajuste en algunos casos, aquí probablemente limitó la capacidad predictiva de los árboles dentro del ensamble.En resumen: -El modelo de sklearn muestra mejoras sobre el árbol manual. -Su rendimiento fue inferior al bagging manual posiblemente por una configuración del parámetro max_features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTC_VZHMlNgQ"
   },
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para regresión  y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1743867766073,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "Z8ueCI7wlNgQ",
    "outputId": "cdcaebe0-f8f5-4a76-bfed-53453c9b3d2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo Random Forest: 1618.40\n",
      "MAE del modelo Random Forest: 1200.39\n"
     ]
    }
   ],
   "source": [
    "# Celda 4\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Entrenar Random Forest Regressor\n",
    "# -------------------------------\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,  # Número de árboles\n",
    "    max_depth=5,  # Profundidad máxima del árbol\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# Métricas de desempeño\n",
    "# -------------------------------\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"RMSE del modelo Random Forest: {rmse_rf:.2f}\")\n",
    "print(f\"MAE del modelo Random Forest: {mae_rf:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoM_8F5flNgR"
   },
   "source": [
    "El modelo de Random Forest obtuvo un RMSE de 1618.40 y un MAE de 1200.39 en el conjunto de prueba, logrando el mejor RMSE de todos los modelos evaluados hasta ahora. Random Forest combina bagging (ensamble de árboles sobre muestras bootstrap) con una aleatorización adicional: en cada división del árbol, se considera solo un subconjunto aleatorio de variables. Esto: -Aumenta la diversidad entre los árboles, -Reduce el sobreajuste, -Y mejora la generalización del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rycK5IWUlNgR"
   },
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99442,
     "status": "ok",
     "timestamp": 1743868103239,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "WumQw4MglNgR",
    "outputId": "7fad14b9-c999-4732-bcbe-3967d8971b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Mejores hiperparámetros: {'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "RMSE del modelo optimizado: 1564.25\n",
      "MAE del modelo optimizado: 1147.20\n"
     ]
    }
   ],
   "source": [
    "# Celda 5\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Definir los valores a probar en cada hiperparámetro\n",
    "# -------------------------------\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],        # Cantidad de árboles\n",
    "    'max_depth': [3, 5, 10, None],         # Profundidad máxima del árbol\n",
    "    'max_features': ['sqrt', 'log2', None] # Cantidad de features por árbol\n",
    "}\n",
    "\n",
    "# Modelo base\n",
    "rf_base = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Búsqueda de hiperparámetros con validación cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                  # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar búsqueda\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener mejores hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Mejores hiperparámetros: {best_params}\")\n",
    "\n",
    "# Entrenar modelo con los mejores parámetros encontrados\n",
    "rf_optimized = RandomForestRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    max_features=best_params['max_features'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_optimized.fit(X_train, y_train)\n",
    "y_pred_rf_opt = rf_optimized.predict(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# Métricas de desempeño\n",
    "# -------------------------------\n",
    "rmse_rf_opt = np.sqrt(mean_squared_error(y_test, y_pred_rf_opt))\n",
    "mae_rf_opt = mean_absolute_error(y_test, y_pred_rf_opt)\n",
    "\n",
    "print(f\"RMSE del modelo optimizado: {rmse_rf_opt:.2f}\")\n",
    "print(f\"MAE del modelo optimizado: {mae_rf_opt:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ug5rKZZklNgS"
   },
   "source": [
    "Tras aplicar una búsqueda exhaustiva de hiperparámetros (max_depth, max_features, y n_estimators), el mejor modelo encontrado fue: -max_depth: 10 -max_features: 'sqrt' -n_estimators: 200 Este modelo alcanzó un RMSE de 1564.25 y un MAE de 1147.20, lo cual representa la mejor precisión obtenida en todo el ejercicio, superando claramente los modelos anteriores, tanto manuales como automáticos. ¿Cómo afectó cada hiperparámetro? max_depth = 10: Limitar la profundidad evitó que los árboles crecieran demasiado y se sobreajustaran. Esto favoreció la generalización, mejorando eldesempeño sobre el conjunto de prueba. max_features = 'sqrt': Esta configuración obliga a que cada división considere solo un subconjunto aleatorio de variables, lo que aumenta la diversidad entre árboles y reduce la varianza del ensamble. n_estimators = 200: Al aumentar el número de árboles, se logró una mayor estabilidad y reducción del error sin caer en sobreajuste, gracias a la regularización del resto de los hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCKTApB5lNgS"
   },
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de regresión con la librería sklearn y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1743867909897,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "vWT-W-KNlNgS",
    "outputId": "ff509291-9cd7-4203-d5c6-bb07fd94803a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo XGBoost: 1547.19\n",
      "MAE del modelo XGBoost: 1131.11\n"
     ]
    }
   ],
   "source": [
    "# Celda 6\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Entrenar XGBoost Regressor\n",
    "# -------------------------------\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=100,   # Número de árboles\n",
    "    max_depth=5,        # Profundidad máxima del árbol\n",
    "    learning_rate=0.1,  # Tasa de aprendizaje\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# Métricas de desempeño\n",
    "# -------------------------------\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"RMSE del modelo XGBoost: {rmse_xgb:.2f}\")\n",
    "print(f\"MAE del modelo XGBoost: {mae_xgb:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r03k4DDzlNgT"
   },
   "source": [
    "El modelo de regresión implementado con XGBoost alcanzó un RMSE de 1547.19 y un MAE de 1131.11, logrando el mejor desempeño general entre todos los modelos evaluados.\n",
    "\n",
    "XGBoost utiliza el principio de boosting, donde los árboles se construyen secuencialmente, y cada uno intenta corregir los errores del anterior. Además, incorpora técnicas avanzadas de regularización y permite un control muy fino sobre el aprendizaje, lo que favorece una mayor precisión y menor sobreajuste comparado con modelos como Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kzj96lwOlNgT"
   },
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15766,
     "status": "ok",
     "timestamp": 1743867928530,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "grO532tKlNgT",
    "outputId": "d1f41b21-7611-40f8-9ac4-427b4a7d02cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Mejores hiperparámetros: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1}\n",
      "RMSE del modelo optimizado: 1540.68\n",
      "MAE del modelo optimizado: 1131.36\n"
     ]
    }
   ],
   "source": [
    "# Celda 7\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Definir los valores a probar en cada hiperparámetro\n",
    "# -------------------------------\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],  # Controla el tamaño del ajuste en cada iteración\n",
    "    'gamma': [0, 0.1, 0.5, 1],              # Regularización para evitar sobreajuste\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0]     # Porcentaje de features utilizadas en cada árbol\n",
    "}\n",
    "\n",
    "# Modelo base\n",
    "xgb_base = XGBRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "# Búsqueda de hiperparámetros con validación cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                   # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar búsqueda\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener mejores hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Mejores hiperparámetros: {best_params}\")\n",
    "\n",
    "# Entrenar modelo con los mejores parámetros encontrados\n",
    "xgb_optimized = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    gamma=best_params['gamma'],\n",
    "    colsample_bytree=best_params['colsample_bytree'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_optimized.fit(X_train, y_train)\n",
    "y_pred_xgb_opt = xgb_optimized.predict(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# Métricas de desempeño\n",
    "# -------------------------------\n",
    "rmse_xgb_opt = np.sqrt(mean_squared_error(y_test, y_pred_xgb_opt))\n",
    "mae_xgb_opt = mean_absolute_error(y_test, y_pred_xgb_opt)\n",
    "\n",
    "print(f\"RMSE del modelo optimizado: {rmse_xgb_opt:.2f}\")\n",
    "print(f\"MAE del modelo optimizado: {mae_xgb_opt:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLcFVizelNgU"
   },
   "source": [
    "Comparado con XGBoost sin optimizar, este modelo TUVO levemente menor error (RMSE y MAE más bajos). RMSE 1540.68vs 1547.\n",
    "\n",
    "Impacto de cada hiperparámetro:\n",
    "\tLearning_rate: Controla cuánto cambia el modelo en cada iteración. Un valor alto puede hacer que el modelo aprenda rápido pero con menos estabilidad.\n",
    "\tgamma: Ayuda a reducir el sobreajuste penalizando particiones innecesarias en los árboles.\n",
    "\tcolsample_bytree: Controla el porcentaje de features utilizadas en cada árbol, reduciendo la correlación entre árboles y mejorando la generalización.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrePW-ndlNgU"
   },
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1743868103327,
     "user": {
      "displayName": "Edna Mora",
      "userId": "11417440768872342315"
     },
     "user_tz": 300
    },
    "id": "Wf_3NA9zlNgU",
    "outputId": "0496a44e-2000-4a90-97df-5eece307f93f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 8\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_title(\"Comparación RMSE de modelos\")\n",
    "ejeX = ['Random Forest', 'Randm Forest Opt', 'XGBoost', 'XGBoost Opt']\n",
    "ejeY = [rmse_rf, rmse_rf_opt, rmse_xgb, rmse_xgb_opt]\n",
    "ax.bar(ejeX,ejeY)\n",
    "def addlabels(x,y,plotP):\n",
    "    for i in range(len(x)):\n",
    "        plotP.text(i,y[i],y[i])\n",
    "addlabels(ejeX,ejeY,plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vi2lhX01lNgV"
   },
   "source": [
    "### Comparación entre Random Forest y XGBoost\n",
    "\n",
    "-**Precisión y desempeño**\n",
    "\n",
    "-El modelo Random Forest calibrado obtuvo un RMSE de 1564.25 y MAE de 1147.20. -El modelo XGBoost calibrado logró un RMSE de 1540.68 y MAE de 1131.36. Ambos modelos ofrecen un desempeño excelente, pero XGBoost superó ligeramente a Random Forest en ambas métricas, consolidándose como el mejor modelo del análisis.\n",
    "\n",
    "-Ventajas de XGBoost sobre Random Forest -Aprendizaje secuencial (boosting): XGBoost construye árboles corrigiendo los errores del anterior, lo que le da mayor capacidad de adaptación y precisión. -Regularización incorporada (gamma, lambda, alpha): permite controlar el sobreajuste de forma más fina. -Velocidad y eficiencia computacional: está altamente optimizado para tareas de regresión con grandes volúmenes de datos.\n",
    "\n",
    "-Ventajas de Random Forest -Más fácil de configurar: tiene menos hiperparámetros críticos. -Menor riesgo de sobreajuste extremo si se calibra correctamente. -Es más robusto ante ruido cuando no se afina demasiado.\n",
    "\n",
    "-Desventajas de cada uno -Random Forest puede tener dificultades para captar relaciones muy complejas entre variables si no se calibra bien, y puede ser menos preciso en tareas donde los errores acumulativos son clave.\n",
    "\n",
    "-XGBoost, si no se calibra cuidadosamente, puede sobreajustar fácilmente por su alto poder expresivo y depender más del ajuste de parámetros como learning_rate y gamma.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparación y Conclusión:\n",
    "-Ambos modelos son poderosos, pero XGBoost calibrado ofrece una ventaja competitiva en precisión gracias a su arquitectura basada en boosting y capacidad de regularización. Sin embargo, Random Forest sigue siendo una excelente opción si se busca robustez, simplicidad y buen desempeño sin tanto esfuerzo de calibración.\n",
    "\n",
    "Tambien se pueden incluir algunas transformaciones adicionales de las variables para mejorar el desempeño de los modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKPEAVJ_lNgV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRLVCJ3klNgV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
